# Lecture 22 â€” GPU Programming (CUDA)

## Roadmap

This lecture is about understanding how to write GPU kernels. We have an
exercise which will help you get a better feel for

* warmup time;
* an active data parallelism exercise; and
* live coding about kernels

## Warm-up overheads [5 minutes]

This exercise works on your own or with a partner.

1. How long does it take to get from Parliament Hill in Ottawa to Gare Centrale
in Montreal? Estimate the time by car and by plane. Assume that you are driving
from Parliament Hill to the Ottawa airport and also from Montreal Trudeau
airport to Gare centrale. Don't forget that you have to clear security and be
there on time to board.

2. Same question, but from the Davis Centre at the University of Waterloo to the
Ferry Building in San Francisco. To keep things simple, let's say that you are
taking a taxi or rideshare to and from the airport.

## Data parallelism (10 minutes)

* The unit of execution in a GPU is called a *warp*, which executes SIMT (Single
  Instruction Multiple Thread) instructions. There can be multiple units of
  execution in a given GPU

* Each data element is a work item. CUDA spawns a thread for each work item,
  with a unique thread ID; they are grouped into blocks (see [Grid of Thread
  Blocks](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#thread-hierarchy-grid-of-thread-blocks))

* Discuss the memory types (A useful material may be
  [link](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-hierarchy))
  * private memory (per-thread registers, etc.)
  * local memory (shared within blocks)
  * global memory (accessable by all threads as well as the host)
  * texture memory (read-only, optimized for different memory usages)
  * constant memory (read-only, , optimized for different memory usages)

* Branches. In practice, the hardware will execute all branches that any thread
  in a warp executed (due to SIMT)

* Atomic functions

## Live coding: kernels (10 minutes)

* show the simple sum kernel and run it (see `live-coding/L22/`)

## Activity

TODO: find a better example, maybe the password cracking example from L24.

Project the N-body problem code from L22. Each student is a work-item. Assign a
grid number to each student on the 2D grid induced by the classroom layout. So,
of course, each student runs a thread. You can pick your inputs arbitrarily,
just do the calculation. Group into blocks. Blocks share memory. Only some
number of students can run simultaneously (limited by GPU characteristics).

## Guided discussion: writing a kernel well (10 minutes)

Run through the discussion in the L22 notes under "Writing a kernel well" and
collectively develop the points there.
