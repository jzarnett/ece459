# Lecture 11 â€” Lock Convoys, Atomics, Lock-Freedom

## Lock Convoys

Activity: given a lock (say a piece of paper), 3 students play as threads
with the same priority, of which 2/3 need the lock and 1/3 doesn't;
one additional student plays as the scheduler.

- Once the lock is free, a random thread picks up the lock then informs the
  scheduler to pick the next thread to run.
- The scheduler doesn't see which thread owns the lock. It picks the next-to-run
  thread randomly.

The possible actions for the threads are:
- Threads that need the lock: attempt to acquire the lock/wait for the lock,
   and eventually release the lock.
- Thread that doesn't need the lock: just runs normally (gets a bunch of execution.)

Let's see how many times the scheduler picks the wrong thread to run.

## Try-lock

```rust
use std::sync::Mutex;
use std::thread;

fn main() {
    let mut retries = 0;
    let retries_limit = 10;
    let counter = Mutex::new(0);

    loop {
        if retries < retries_limit {
            let l = counter.try_lock();
            // ^ try_lock helps since if A is going to release the critical
            // section, B does not immediately become the owner (since it is not
            // yet its turn). A may keep running and A might even get the
            // critical section again during the same time slice before B tries
            // to acquire the lock (and may succeed).
            if l.is_ok() {
                *l.unwrap() = 1;
                break;
            } else {
                retries = retries + 1;
                thread::yield_now();
                // ^ give up the remaining time slice if try_lock failed
            }
        } else {
            // in case the critical section belongs to a low priority thread and
            // we need the current thread to be blocked so the low priority
            // thread can run
            *counter.lock().unwrap() = 1;
            break;
        }
    }
    println!("done");
}
```

## Atomics

### load and store

```rust
use std::sync::atomic::{AtomicBool, Ordering};

fn main() {
    let b = AtomicBool::new(false);
    b.store(true, Ordering::SeqCst);
    println!("{}", b.load(Ordering::SeqCst));
}
```

### compare and exchange

Implementing a spinlock

```rust
use std::hint;
use std::sync::atomic::{AtomicBool, Ordering};

fn main() {
    let my_lock = AtomicBool::new(false);
    // ... Other stuff happens
    while my_lock.compare_exchange(false, true,
                                   Ordering::SeqCst, Ordering::SeqCst) == Err(true) {
        // compare_exchange(current, new, ...)
        //     success: Ok(previous)
        //     fail: Err(previous)
        // The lock was 'true', someone else has the lock, so try again
        hint::spin_loop();
        // ^ The spin loop is a hint to the CPU that we're waiting, but probably
        // not for very long
    }
    // Inside critical section
    my_lock.store(false, Ordering::SeqCst);
    println!("Done!");
}
```

### ABA problem

## Lock Freedom

Discuss about non-blocking, blocking, lock-free, and wait-free. See
<https://www.justsoftwaresolutions.co.uk/threading/non_blocking_lock_free_and_wait_free.html>

Talk about the lock-free stack (see the lecture notes) if there's time

Question: Are lock-free programming techniques always better for performance?

# After-action report, huanyi, 06Feb23

Only briefly talked about the `loop` inside the lock-free stack, but since
that's the major component so I guess it's ok.

# After-action report, plam, 10Feb23

Better specified the lock convoy example. (Now improved in the text above.)

Typed in the code examples.

Did not talk about ABA. Briefly mentioned lock freedom, but not in great detail.
