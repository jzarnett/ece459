# Lecture 18 â€” Optimizing the Compiler

## Measurement Infrastructure

The optimization workflow is just to make a potential change to the compiler
(ideally hotspots) and then benchmark and profile it. Let's check out
<https://perf.rust-lang.org> and see how `rustc` gets improved.

### Benchmark selection

Question: How do you select appropriate benchmarks?

(Answer in the lecture notes)

### Data collection

Discussion: What are the data you think important for optimization? (time,
cache, memory usage, etc.)

(Mention the tools and maybe demo it? `perf` seems not available on ece machines
though)

## Case Studies: Micro-optimizations

In addition to mention the cases in the lecture notes, use <https://godbolt.org>
to show how LLVM backend will emit inline code rather than a call to `memcpy`.

```rust
pub struct Var {
    a: [i128; 9]
    // ^ change 9 to a smaller number and see what happens
}

pub fn bar(x: Var) -> Var {
    let y = x;
    y
}
```

Question: what is the perf tradeoff involved with boxing (putting object on
heap), i.e. when does it succeed and when does it fail.

## Negative Results

Simpler does not necessarily mean faster.

## Architecture-level Changes

### Pipelined compilation

This is always enabled in the latest version (see
[here](https://doc.rust-lang.org/cargo/reference/config.html#buildpipelining))

```
         meta                meta
[-libA----|--------][-libB----|--------][-binary-----------]
0s        5s       10s       15s       20s                30s
```

Question: in the above graph, `Cargo` invokes `rustc` to build libA, then libB,
then the binary. Given that libB only relies on the metadata of libA emitted at
5s, how do you speed up the process?

See the longer discussion
[here](https://rust-lang.github.io/compiler-team/working-groups/pipelining/NOTES/)

### Linking

Using an appropriate linker can reduce the build time.

## Other

Good to read: <https://nnethercote.github.io/perf-book/title-page.html>

# After-action report, plam, 6 Mar 2023

Mostly lecture/with audience participation. Showed slides for micro-opts
and architecture-level changes.