# Lecture 8 — Cache Coherency

## Roadmap

We will talk about cache coherency from the point of view of a user (not
implementer) and walk through some examples.

## Mini-lecture

Cache Coherency means

- the values in all caches are consistent; and

- to some extent, the system behaves as if all CPUs are using shared memory.

Initially in main memory: `x = 7`.

1. CPU1 reads `x`, puts the value in its cache.
2. CPU3 reads `x`, puts the value in its cache.
3. CPU3 modifies `x := 42` (writes to memory as well)
4. CPU1 reads `x := 7` from its cache (❌)
5. CPU2 reads `x`. Which value does it get?

To know something has changed

- check before use

- get notified

## Snoopy coherence mechanism

Caches are spying on each other. It is workable because they have a shared bus
(see how a system bus works <https://en.wikipedia.org/wiki/System_bus>). The
*write-invalidate protocols* and *write-update protocols* make use of this
mechanism. Because write-invalidate protocol is the most common protocol, so we
will only talk about that here.

### Write-Through Protocol

The protocol for implementing such caches looks like this. There are two
possible states, **valid** and **invalid**, for each cached memory location.
Events are either from a processor (**Pr**) or the **Bus**. Actions will be
either a **Rd** (read) or **Wr** (write). We then implement the following state
machine.

|State   | Observed | Generated | Next State|
|--------|----------|-----------|-----------|
|Valid   | PrRd     |           | Valid     |
|Valid   | PrWr     | BusWr     | Valid     |
|Valid   | BusWr    |           | Invalid   |
|Invalid | PrWr     | BusWr     | Valid     |
|Invalid | PrRd     |           | Valid     |

Therefore, for the above example, CPU1 will snoop and mark data as invalid in
step 3. In steps 4 and 5, CPU1 and CPU2 both read `x` from main memory.

### Write-Back Protocols

This is used to merge multiple writes into a single flush. At minimum, we need
support in hardware for a "dirty" bit, which indicates that our data has been
changed but not yet been written to memory.

#### MSI

**M**odified, **S**hared, and **I**nvalid

##### Activity

Walk through the MSI protocol using the same (`x = 7`) example above. (See the
MSI example in the lecture note)

#### MESI

 **M**odified, ***E***_xclusive_, **S**hared, and **I**nvalid

#### MESIF

 **M**odified, **E**xclusive, **S**hared, **I**nvalid, and ***F***_orward_

## False Sharing

False sharing is something that happens when our program has two unrelated data
elements that are mapped to the same cache line/location. It seems the cache is
shared but in fact it is not. (See `L08/false_sharing`)

```bash
h365chen@eceTesla1:~/false_sharing$ make measure
g++ -o with_false_sharing false_sharing_10.cpp -lboost_thread -lpthread -O3
g++ -o without_false_sharing false_sharing_100.cpp -lboost_thread -lpthread -O3
hyperfine -w 3 -r 3 ./with_false_sharing
Benchmark #1: ./with_false_sharing
  Time (mean ± σ):      1.097 s ±  0.124 s    [User: 2.139 s, System: 0.001 s]
  Range (min … max):    0.991 s …  1.233 s    3 runs

hyperfine -w 3 -r 3 ./without_false_sharing
Benchmark #1: ./without_false_sharing
  Time (mean ± σ):     256.1 ms ±   0.3 ms    [User: 504.7 ms, System: 0.0 ms]
  Range (min … max):   255.9 ms … 256.5 ms    3 runs
```

For the `10` case, the two threads (on two cores) keep invalidating the cache of
each other, since they are touching the same cache line.

# After-action report, plam, 27Jan23

Worked through the write-through and MSI protocols. Probably worth doing in person.

Ran the false sharing example. Could have had better explanation.

# after-action, huanyi, 26Jan2024

Worked through the write-through protocol and showed how it could avoid reading
invalid data on the example. Talked about other protocols but did not go into
much detail.

Ran the false sharing example and talked about why there was a performance
difference. One student asked how we can know that the two vectors are put into
one cache line.
