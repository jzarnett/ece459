# Lecture 31 — Introduction to Queueing Theory

## Roadmap

Exercises on queueing theory. Since I'm not going to lecture, we can work
through the examples. These examples are from:

* Mor Harchol-Balter. *Performance Modeling and Design of Computer Systems*.
  Cambridge University Press, 2013.

## Doubling the Arrival Rate [5 minutes]

Imagine we have a system with one CPU that serves a queue of jobs in
First-Come-First-Served (FCFS) order with an arrival rate λ of 3 jobs per
second. Each job takes some amount of time and resources, but we can ignore the
particulars for right now. Suppose the average service rate μ is 5 jobs per
second (or stated another way, the average job requires 0.2s to service). The
system is not overloaded: 3 jobs per second arriving is less than 5 jobs per
second being serviced. Our terminology for describing the mean response time
will be E[T].

Suppose now that your boss says that tomorrow the arrival rate will double. If
you do nothing, you can imagine, there will be a problem: we would have 6 jobs
arriving per second, on average, to a system that can service, on average, 5
jobs per second. You have been allocated some budget to replace the CPU with a
faster one, and you should choose one so that the jobs still have a mean
response time of E[T].

![](../images/qt-example1.png)

That is, customers should not notice the increase in arrival rate. So, should we
(1) double the CPU speed; (2) more than double the CPU speed; or (3) less than
double the CPU speed?

## Understanding Bottlenecks (Closed Systems) [5 minutes]

Let's try this one. There are always N=6 jobs running at a time. As soon as a
job completes, a new one is started (this is called a *closed system*). Each job
goes through to be processed on one of two servers (and it is 50-50 where the
job ends up), each of which has a service time μ of 1 job per 3 seconds. Again,
depicted below:

![](../images/qt-example2.png)

What happens if we replace server 1 with something twice as fast (2 jobs per 3
seconds)? What about increasing N? Why is this happening?

What if we drop N?

## Replacing Closed with Open? [5 minutes]

OK, what if we had an open system instead?


![](../images/qt-example2-2.png)

And what if we replaced server 1 now? What does that do to E[T]?

## Horse-Sized Duck vs Duck-Sized Horse [5 minutes]

A third example, this time addressing directly the question of do we want one
fast server or n slower ones? Horse-sized duck and duck-sized horses jokes
aside, what is better if we want to minimize the mean response time when we have
non-preemptable jobs (i.e., once started, a job has to run to completion and
cannot be interrupted):

![](../images/qt-example3.png)

* Think about the variability of job sizes. Imagine you are at the grocery store
  and most people have 12 items or fewer and there's one guy who's buying 85
  items. You don't want to be standing in line with milk and eggs behind someone
  who is trying to buy six of everything, do you?
* What if the load is low?
* What if jobs are interruptible (preemptible)?

## Load Balancing [5 minutes]

Imagine your typical ``server farm''---you have *n* servers that are all
responsible for handling incoming requests. Let's imagine all servers are the
same (or close enough). There are a few different task assignment
policies---ways in which we can assign work to servers:

* Random: Exactly what it sounds like.
* Round-Robin: The ith job goes to host i modulo n.
* Shortest-Queue: The job goes to the server with the shortest queue.
* Size-Interval-Task-Assignment: Short jobs go to one server, medium to another, long to another...
* Least-Work-Left: A job goes to the server that has the least total remaining work, where work is the sum of the size of the jobs.
* Central-Queue: Rather than being assigned to a host directly, when a server needs work to do, it gets the first job in the central queue.

Which of these policies yields the lowest mean response time?

```
¯\_(ツ)_/¯
```

## Red Line Overload [5 minutes]

* What happens if, on average, more jobs arrive than the system can handle?
* OK, let's say that doesn't happen. Now, what happens to throughput when you
  just increase average service rate μ but you leave incoming job rate the same?
* What if it's a closed system and you increase μ?

## A final closed-system mystery [5 minutes]

Not that open networks are particularly intuitive, but closed networks can kind
of mess with our intuition in general. Imagine we have a closed system with
Multiprogramming Level (MPL) of N as below:

![](../images/tandem-closed.png)

What is the throughput here?

# After-action report, plam, 24 Mar 2023

Worked through the examples. Y'know, actually, the first closed system exercise
is not completely clear to me: you make a server twice as fast, and then what
happens? Hmm.

# After-action report, huanyi, 22Mar24

Covered by Jeff.
