\input{configuration}

\title{Lecture 26 ---Profiling and Scalability}

\author{Jeff Zarnett\\ \small \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}


\begin{frame}
\frametitle{Who Can It Be Now?}

\begin{center}
	\includegraphics[width=0.6\textwidth]{images/n-body-go-brrrrr.png}
\end{center}

We usually assume that CPU is the problem... but is that true?

Let's also relate this to scalability: max users or transactions.

Not a hypothetical scenario!

\end{frame}



\begin{frame}
\frametitle{Profiling and Scalability}


Goal: scale number of users,

\[ 1 \rightarrow 100 \rightarrow 10 000 000. \]

Be more fast? \\
You have other options too\ldots


\begin{center}
	\includegraphics[width=0.2\textwidth]{images/Rebel_Yell.jpg}\\
	\hfill ``In the midnight hour, she cries 'more, more, more''' - Billy Idol
\end{center}

\end{frame}


\begin{frame}
\frametitle{Don't Guess, Measure}


\begin{center}
	\includegraphics[width=0.4\textwidth]{images/testinprod.png}
\end{center}


As always, we want to measure (profile).\\[1em]
3 principles to think about\\
when going from dev to production:




\end{frame}



\begin{frame}
\frametitle{Hardware Principle}


\begin{changemargin}{2cm}
Scalability testing $\neq$  QA testing.\\[1em]

Dev + QA on local computer.\\
Your concerns: Is it right? Is it fast enough?\\[1em]

Fine, but it's no way to test if it scales. 
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Hardware Principle}


\begin{changemargin}{2cm}
Test on prod-like machines.\\[1em]
Low-end systems have very different limiting factors. \\[1em]
Your laptop: limited by 16GB of RAM.\\
Prod server: 128GB of RAM.\\[1em]
So you might spend a great deal of time worrying about RAM usage and it just doesn't matter.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Reality Principle}

\begin{center}
	\includegraphics[width=0.5\textwidth]{images/qa.png}
\end{center}


\end{frame}


\begin{frame}
\frametitle{Reality Principle}

\begin{changemargin}{2cm}
Use a ``real'' workload.\\
(As far as possible).\\[1em]
Maybe not actual live customer data,\\
but try to come close.\\[1em]
Limited test data/scenarios $\Rightarrow$ \\
\qquad inaccurate test results.\\[1em]
Your tests run summary reports occasionally\ldots\\
your users might run them every hour. 
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Volume Principle}

\begin{changemargin}{2cm}
``More is the new more.'' 

Lighter workloads OK for regression testing. 

To see how your system performs under pressure, you actually need to put it under pressure. 

Can simulate pressure by limiting RAM or\\ running something very CPU-intensive concurrently,\\
but it's just not the same.

These tests also  of great interest to the customers, who would like to know that you can deliver. 
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Reproducibility and Regression Testing}


\begin{changemargin}{2cm}
Science rule 1: results need to be reproducible!

Good programming practice: must run unit tests,\\
and re-run to make sure it all works. 

Old (solved) performance issues also bad.

Or a new change that slows the whole program down still more bad.
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Elementary, My Dear Watson!}


\begin{changemargin}{1cm}
\begin{quote}
\textit{It is a capital mistake to theorize before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts.}
\end{quote}
\hfill --- Sherlock Holmes\\
\hfill (\textit{A Scandal in Bohemia}; Sir Arthur Conan Doyle)
\end{changemargin}

\begin{center}
	\includegraphics[width=0.3\textwidth]{images/jeremybrett.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Collect Evidence}


\begin{changemargin}{1cm}
Who's to blame?
\begin{enumerate}
	\item CPU
	\item Memory
	\item Disk
	\item Network
	\item Locks
\end{enumerate}

These are, obviously, \\
categories rather than specific causes.
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Blame the CPU}


\begin{changemargin}{1cm}
CPU is probably the easiest of these to diagnose. \\[1em]
\texttt{htop}, Task Manager, etc. will tell you if CPU hosed.\\
Look at the \%CPU columns\\
and see where all your CPU is going. 
\end{changemargin}


\end{frame}



\begin{frame}[fragile]
\frametitle{Overwatch}


\begin{changemargin}{1cm}
Still, that tells you about right now; \\
what about the long term average? \\[1em]

Checking with my machine ``Loki'', that has since ascended to Valhalla:\\[1em]

{\scriptsize
\begin{verbatim}
top - 07:28:19 up 151 days, 23:38,  8 users,  load average: 0.87, 0.92, 0.91
\end{verbatim}
}

Those last three numbers are the one, five, and fifteen minute averages of CPU load, respectively. \\[1em]

Lower numbers mean less CPU usage and a less busy machine. 
\end{changemargin}

\end{frame}




\begin{frame}
\frametitle{Interpreting Load Numbers}


\begin{changemargin}{1cm}
Picture a single core of a CPU as a lane of traffic. 

You are a bridge operator and so you need to monitor how many cars are waiting to cross that bridge. 

If no cars are waiting, traffic is good and drivers are happy. 

If there is a backup of cars, then there will be delays.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Single-CPU Load Scheme}


\begin{changemargin}{1cm}
\begin{enumerate}
	\item 0.00 means no traffic. \\
    Anything between 0.00 and 0.99 means we're under capacity and there will be no delay.\\[1em]
	\item 1.00 means we are exactly at capacity. \\
    Everything is okay, but if one more car shows up, there will be a delay.\\[1em]
	\item Anything above 1.00 means there's a backup (delay). \\
    If we have 2.00 load, then the bridge is full and there's an equal number of cars waiting to get on the bridge. 
\end{enumerate}
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Car Analogy}

\begin{center}
	\includegraphics[width=\textwidth]{images/car-analogy.png}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Is it a Problem?}


\begin{changemargin}{1cm}
$\ge$ 1.00 isn't necessarily bad, but you should be concerned if there is consistent load of 1.00 or above. 

$<$ 1.00 but getting close to it: you know how much room you have to scale things up.

$>$ 0.70 then it's probably time to investigate.

$\ge$ 1.00 consistently we have a serious problem. 

5.00: this is a red alert situation.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Multicore}


\begin{changemargin}{1cm}
Now this is for a single CPU---if you have a load of 3.00 and a quad core CPU, this is okay. 

Traffic analogy: four lanes of traffic, of which 3 are being used to capacity.

So we have a fourth lane free and it's as if we're at 75\% utilization on a single CPU.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Disk? Or Memory?}


\begin{changemargin}{1cm}
How to tell? Look at disk utilization. \\[1em]

Not enough RAM $\Rightarrow$ swapping, bad perf, no scalability.\\[1em]

(In the worst case.)\\[1em]

You can ask via \texttt{top} about how much swap is being used, but that's probably not the interesting value. 

{\scriptsize
\begin{verbatim}
KiB Mem:   8167736 total,  6754408 used,  1413328 free,   172256 buffers
KiB Swap:  8378364 total,  1313972 used,  7064392 free.  2084336 cached Mem
\end{verbatim}
}
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Misleading Memory}


\begin{changemargin}{1cm}
Why? Memory being ``full'' does not necessarily mean anything bad. \\[1em]

It means the resource is being used to its maximum potential, yes, but there is no benefit to keeping a block of memory open for no reason. (Or stockpiling late days).\\[1em]

Also, memory is unlike CPU; if there's nothing for the CPU to do, it will just idle (low power state).
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Really, Dvorak, Really?}


\begin{changemargin}{1cm}
Memory won't ``forget'' data if it doesn't happen to be needed right now---data will hang around in memory until there is a reason to move or change it. 

So freaking out about memory appearing as full is kind of like getting all in a knot about how ``System Idle Process'' is hammering the CPU\ldots
\end{changemargin}

\end{frame}




\begin{frame}
\frametitle{Page Faults}


\begin{changemargin}{1cm}
You can also ask about page faults, with the command
\begin{center}
\texttt{ps -eo min\_flt,maj\_flt,cmd}
\end{center}

Major page faults: had to fetch from disk. 

Minor page faults: had to copy a page from another process. 

The output of this is too big even for the notes.

This is process-lifetime data.
\end{changemargin}
\end{frame}



\begin{frame}[fragile]
\frametitle{Swapping Report}


\begin{changemargin}{1cm}
What you really want is to ask Linux for a report on swapping:
\end{changemargin}
\vspace*{-2em}
{\scriptsize
\begin{verbatim}
jz@Loki:~$ vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0 1313972 1414600 172232 2084296    0    0     3    39    1    1 27  1 72  0  0
 0  0 1313972 1414476 172232 2084296    0    0     0    21  359  735 19  0 80  0  0
 0  0 1313972 1414656 172236 2084228    0    0     0   102  388  758 22  0 78  0  0
 4  0 1313972 1414592 172240 2084292    0    0     0    16  501  847 33  0 67  0  0
 0  0 1313972 1412028 172240 2084296    0    0     0     0  459  814 29  0 71  0  0
\end{verbatim}
}

\end{frame}



\begin{frame}[fragile]
\frametitle{Swapping Report with Actual Swapping}

{\small
\begin{verbatim}
  procs                      memory    swap          io     system cpu
r  b  w   swpd   free  buff cache  si  so   bi   bo   in    cs us  sy  id
. . .
1  0  0  13344   1444  1308 19692   0 168  129   42 1505   713 20  11  69
1  0  0  13856   1640  1308 18524  64 516  379  129 4341   646 24  34  42
3  0  0  13856   1084  1308 18316  56  64   14    0  320  1022 84   9   8
\end{verbatim}
}

\end{frame}



\begin{frame}
\frametitle{Skip to Disk}


\begin{changemargin}{1cm}
Looking at disk might seem slightly redundant if memory is not the limiting factor. 

After all, if the data were in memory it would be unnecessary to go to disk in the first place. 

Still, sometimes we can take a look at the disk and see if that is our bottleneck.
\end{changemargin}

\end{frame}




\begin{frame}[fragile]
\frametitle{Looking at Disk Usage}

{\tiny
\begin{verbatim}
jz@Loki:~$ iostat -dx /dev/sda 5 
Linux 3.13.0-24-generic (Loki) 	16-02-13 	_x86_64_	(4 CPU)

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
sda               0.24     2.78    0.45    2.40    11.60   154.98   116.91     0.17   61.07   11.57   70.27   4.70   1.34
\end{verbatim}
}


\begin{changemargin}{1cm}
Last column \%util tells us what we want to know.
\end{changemargin}

\end{frame}



\begin{frame}[fragile]
\frametitle{Network}


\begin{changemargin}{1cm}
We can ask about the network with \texttt{nload}. 
 
You get a nice little graph if there is anything to see. 

But you'll get the summary, at least:

\begin{verbatim}
Curr: 3.32 kBit/s
Avg: 2.95 kBit/s
Min: 1.02 kBit/s
Max: 12.60 kBit/s
Ttl: 39.76 GByte                                                                                       \end{verbatim}
\end{changemargin}
\end{frame}


\begin{frame}
\frametitle{Locks}

Maybe our code is slow because we are waiting for locks?

\begin{center}
	\includegraphics[width=0.5\textwidth]{images/letmein.png}
\end{center}

Out of scope: deadlock detection.

\end{frame}


\begin{frame}
\frametitle{How to Find It?}

Unexpectedly low CPU usage not explained by I/O-waiting?

Many threads blocked?

No magical \texttt{locktrace} tool -- may need our own tracing.

\texttt{perf lock} is for kernel locks; VTune costs money.

\end{frame}


\begin{frame}
\frametitle{Probably it's CPU}

Most of our discussion will be about CPU though.

Why? That's probably what it is!


\end{frame}



\end{document}